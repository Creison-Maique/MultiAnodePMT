{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as ticker\n",
    "import heapq\n",
    "import os\n",
    "from decimal import Decimal\n",
    "np.set_printoptions(threshold=np.nan) \n",
    "home_path = os.getcwd().replace('BC1/notebooks','')\n",
    "import cPickle as pickle\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import copy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"separate_BC.json\", \"r\") as read_file:\n",
    "    json_file = json.load(read_file)\n",
    "name_json = json_file[\"file_name\"]\n",
    "split = name_json.split('.')\n",
    "run_number = split[1][2:7]\n",
    "single_anode_channel = int(json_file[\"single_anode_channel\"])\n",
    "number_tubes_json = len(json_file[\"tubes\"])\n",
    "input_name_json = json_file[\"file_name\"]\n",
    "#opening the file\n",
    "dictionary_path = home_path+'processed_data/Dados BC1/'\n",
    "file = open(dictionary_path+input_name_json+'_separate.pkl','rb')\n",
    "results = pickle.load(file)\n",
    "#Path to the channel reading mapping file\n",
    "map_path = home_path+'processed_data/Dados BC1/mapping.txt'\n",
    "pixel_map = np.loadtxt(map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = results[\"DataB\"][\"tensor\"][0][:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_ICA(number_componentes,matrix):\n",
    "    # Compute ICA:\n",
    "    \"\"\"\n",
    "        Private method creating a vector image in a chosen folder\n",
    "        Only for Fast ICA\n",
    "        #note that you need the variable \" ordem \" to desvector_patches\n",
    "        Args:\n",
    "        ----\n",
    "        matriz_method (str): Method that will return a transformation\n",
    "        of an matrix in array\n",
    "        number_componentes(int): Number of components that will be used\n",
    "\n",
    "        Returns:\n",
    "        pesq(array 2D)\n",
    "        -------\n",
    "        \n",
    "    \"\"\"  \n",
    "    rn = np.random.RandomState(0)\n",
    "    ica = FastICA(n_components=number_componentes,algorithm='deflation', fun='logcosh',random_state=rn)\n",
    "\n",
    "    S_ = ica.fit_transform(matrix) \n",
    "    A_ = ica.components_             \n",
    "\n",
    "\n",
    "    #Convert the input to an array.\n",
    "    myarray = np.asarray(S_)\n",
    "    pesq2 = np.asarray(A_)\n",
    "    \n",
    "    pesq= (pesq2-pesq2.min())/(pesq2.max()-pesq2.min())\n",
    "\n",
    "    return pesq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 352.  353.  353.  352.  353.  352.  352.  353.  352.  353.  352.  353.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  353.  352.  353.  353.  352.\n  353.  353.  353.  352.  353.  352.  353.  353.  353.  353.  352.  353.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  352.  353.  353.  352.  353.  353.  354.  354.  354.  354.  354.\n  354.  353.  354.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.\n  353.  354.  354.  353.  354.  354.  353.  354.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.  353.\n  354.  353.  353.  353.  352.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.\n  352.  353.  352.  353.  353.  353.  353.  352.  352.  352.  353.  352.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  352.  352.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.  352.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  352.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.  354.\n  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.\n  353.  353.  353.  354.  353.  353.  354.  353.  354.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  352.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.\n  353.  352.  353.  353.  353.  353.  352.  353.  352.  353.  352.  353.\n  353.  352.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.\n  352.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  352.  353.  353.  353.  354.  353.  353.  353.  354.  355.  354.  354.\n  354.  354.  353.  353.  353.  353.  353.  353.  354.  353.  354.  353.\n  353.  353.  353.  353.  353.  353.  353.  354.  353.  354.  354.  353.\n  353.  354.  354.  353.  354.  353.  354.  353.  353.  353.  353.  353.\n  353.  354.  353.  353.  353.  354.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  352.  353.  353.  353.  352.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  352.  352.  352.  353.  353.  353.  353.\n  353.  352.  352.  353.  353.  352.  353.  352.  353.  352.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  353.  352.  353.  353.  352.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  354.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  352.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.\n  354.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.\n  353.  353.  353.  353.  352.  353.  352.  353.  352.  353.  353.  353.\n  353.  352.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  352.  353.  352.  353.  353.\n  353.  353.  353.  352.  353.  353.  352.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.\n  352.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.\n  352.  353.  353.  352.  353.  353.  353.  353.  352.  353.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  352.  353.  353.  354.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  352.  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  352.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  352.  353.  352.  353.  353.  353.  352.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  352.  353.  352.  353.\n  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  353.  352.\n  353.  353.  352.  353.  352.  353.  353.  353.  352.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.\n  353.  353.  352.  353.  352.  353.  353.  352.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  353.\n  352.  353.  352.  353.  353.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-310d5067e43e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msources03\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalc_ICA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTeste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-c44f57bcbd81>\u001b[0m in \u001b[0;36mcalc_ICA\u001b[0;34m(number_componentes, matrix)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mica\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFastICA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_componentes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deflation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logcosh'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mS_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mA_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Creison/miniconda2/lib/python2.7/site-packages/sklearn/decomposition/fastica_.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mX_new\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \"\"\"\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Creison/miniconda2/lib/python2.7/site-packages/sklearn/decomposition/fastica_.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, compute_sources)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_X_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             compute_sources=compute_sources, return_n_iter=True)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Creison/miniconda2/lib/python2.7/site-packages/sklearn/decomposition/fastica_.pyc\u001b[0m in \u001b[0;36mfastica\u001b[0;34m(X, n_components, algorithm, whiten, fun, fun_args, max_iter, tol, w_init, random_state, return_X_mean, compute_sources, return_n_iter)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;31m# a copy is required only for non whitened data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     X = check_array(X, copy=whiten, dtype=FLOAT_DTYPES,\n\u001b[0;32m--> 274\u001b[0;31m                     ensure_min_samples=2).T\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/Creison/miniconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 352.  353.  353.  352.  353.  352.  352.  353.  352.  353.  352.  353.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  353.  352.  353.  353.  352.\n  353.  353.  353.  352.  353.  352.  353.  353.  353.  353.  352.  353.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  352.  353.  353.  352.  353.  353.  354.  354.  354.  354.  354.\n  354.  353.  354.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.\n  353.  354.  354.  353.  354.  354.  353.  354.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.  353.\n  354.  353.  353.  353.  352.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.\n  352.  353.  352.  353.  353.  353.  353.  352.  352.  352.  353.  352.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  352.  352.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.  352.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  352.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.  354.\n  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.\n  353.  353.  353.  354.  353.  353.  354.  353.  354.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  352.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.\n  353.  352.  353.  353.  353.  353.  352.  353.  352.  353.  352.  353.\n  353.  352.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.\n  352.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  352.  353.  353.  353.  354.  353.  353.  353.  354.  355.  354.  354.\n  354.  354.  353.  353.  353.  353.  353.  353.  354.  353.  354.  353.\n  353.  353.  353.  353.  353.  353.  353.  354.  353.  354.  354.  353.\n  353.  354.  354.  353.  354.  353.  354.  353.  353.  353.  353.  353.\n  353.  354.  353.  353.  353.  354.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  354.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  352.  353.  353.  353.  352.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  352.  352.  352.  353.  353.  353.  353.\n  353.  352.  352.  353.  353.  352.  353.  352.  353.  352.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  353.  352.  353.  353.  352.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  354.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  352.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  354.  353.\n  354.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.\n  353.  353.  353.  353.  352.  353.  352.  353.  352.  353.  353.  353.\n  353.  352.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  352.  353.  353.  352.  353.  352.  353.  353.\n  353.  353.  353.  352.  353.  353.  352.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.\n  352.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.\n  352.  353.  353.  352.  353.  353.  353.  353.  352.  353.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  352.  353.  353.  354.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  352.  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  352.  353.  353.  353.  352.  353.\n  353.  353.  353.  353.  353.  352.  353.  352.  353.  353.  353.  352.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  352.  353.  352.  353.\n  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.  353.  353.\n  353.  352.  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  353.  352.\n  353.  353.  352.  353.  352.  353.  353.  353.  352.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.  352.  353.\n  353.  353.  352.  353.  352.  353.  353.  352.  353.  353.  353.  353.\n  353.  353.  353.  353.  353.  353.  353.  353.  353.  353.  352.  353.\n  353.  353.  353.  352.  353.  353.  353.  353.  353.  353.  352.  353.\n  352.  353.  352.  353.  353.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "sources03=calc_ICA(6,Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=results[\"DataB\"][\"tensor\"][0][:,:,:][0,4]\n",
    "B=results[\"DataB\"][\"tensor\"][1][:,:,:][0,4]\n",
    "C=results[\"DataB\"][\"tensor\"][2][:,:,:][0,4]\n",
    "D=results[\"DataC\"][\"tensor\"][0][:,:,:][0,4]\n",
    "E=results[\"DataC\"][\"tensor\"][1][:,:,:][0,4]\n",
    "F=results[\"DataC\"][\"tensor\"][2][:,:,:][0,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste=np.concatenate([A,B,C,D,E,F], axis=0)\n",
    "teste1=np.concatenate([A,B,C,D,E,F], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.vstack([teste, teste1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1133)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mediann[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
